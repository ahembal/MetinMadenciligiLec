{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Homework-01.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyME3zQSnJT93xmU2SDPaWyc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ahembal/MetinMadenciligiLec/blob/main/Homework_01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X0KhqrgTvCiY"
      },
      "source": [
        "Connectting to drive to read txt file:\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xdc29n7hzz7g",
        "outputId": "9ea9c6d7-9c89-4401-845d-41dfb79fe0dc"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ze6Obwwa0MGd",
        "outputId": "160ffee4-ca93-4e91-9890-1ba2e769562b"
      },
      "source": [
        "cd /content/drive/My Drive/Colab Notebooks"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Colab Notebooks\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JgET529p0QfK",
        "outputId": "531971e2-9de6-43c0-ad58-b1d384f9f199"
      },
      "source": [
        "ls"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Baskaldiran-Insan-Albert-Camus.txt   Homework-01.ipynb     Untitled1.ipynb\n",
            "'Copy of language_modelling.ipynb'    RNNsStillCool.ipynb\n",
            "'Copy of word_embeddings.ipynb'       Untitled0.ipynb\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5hrqzD86stjx"
      },
      "source": [
        "## Part 0\r\n",
        "################################################################################\r\n",
        "# Part 0: Utility Functions\r\n",
        "################################################################################"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7jiJeAGMsWnt"
      },
      "source": [
        "import math, random\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "COUNTRY_CODES = ['af', 'cn', 'de', 'fi', 'fr', 'in', 'ir', 'pk', 'za']\r\n",
        "\r\n",
        "def start_pad(n):\r\n",
        "    ''' Returns a padding string of length n to append to the front of text\r\n",
        "        as a pre-processing step to building n-grams '''\r\n",
        "    return '~' * n\r\n",
        "\r\n",
        "def ngrams(n, text):\r\n",
        "    ''' Returns the ngrams of the text as tuples where the first element is\r\n",
        "        the length-n context and the second is the character '''\r\n",
        "    padded_tokens = []\r\n",
        "    padded_tokens = \"~\"*(n) + text + \".\"\r\n",
        "    if n == 1:\r\n",
        "      lst = [((padded_tokens[i-1]), token) for i, token in enumerate(padded_tokens) if i >= n-1]    # >>> ngrams(1, 'abc') => [('~', 'a'), ('a', 'b'), ('b', 'c')]\r\n",
        "      return  lst[1:]\r\n",
        "    else:\r\n",
        "      lst = [((\"\".join(padded_tokens[i-n:i])), token) for i, token in enumerate(padded_tokens) if i >= n-1] # >>> ngrams(2, 'abc') => [('~~', 'a'), ('~a', 'b'), ('ab', 'c')]\r\n",
        "      return  lst[1:]\r\n",
        "\r\n",
        "def create_ngram_model(model_class, path, n=2, k=0):\r\n",
        "    ''' Creates and returns a new n-gram model trained on the city names\r\n",
        "        found in the path file '''\r\n",
        "    model = model_class(n, k)\r\n",
        "    with open(path, encoding='utf-8', errors='ignore') as f:\r\n",
        "        model.update(f.read())\r\n",
        "    return model\r\n",
        "\r\n",
        "def create_ngram_model_lines(model_class, path, n=2, k=0):\r\n",
        "    ''' Creates and returns a new n-gram model trained on the city names\r\n",
        "        found in the path file '''\r\n",
        "    model = model_class(n, k)\r\n",
        "    with open(path, encoding='utf-8', errors='ignore') as f:\r\n",
        "        for line in f:\r\n",
        "            model.update(line.strip())\r\n",
        "    return model"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uvlL1HJ0sjDv"
      },
      "source": [
        "## Part 1\r\n",
        "################################################################################\r\n",
        "# Part 1: Basic N-Gram Model\r\n",
        "################################################################################"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJdcJlPQsdnf"
      },
      "source": [
        "\r\n",
        "\r\n",
        "class NgramModel():\r\n",
        "    ''' A basic n-gram model using add-k smoothing '''\r\n",
        "\r\n",
        "    def __init__(self, n, k):\r\n",
        "        self.n = n\r\n",
        "        self.k = k\r\n",
        "        self.context_dic = {}\r\n",
        "        self.context_count_dic = {}\r\n",
        "\r\n",
        "    def get_vocab(self):\r\n",
        "        ''' Returns the set of characters in the vocab '''\r\n",
        "        return self.context_count_dic.keys()\r\n",
        "\r\n",
        "    def update(self, text):\r\n",
        "        ''' Updates the model n-grams based on text '''\r\n",
        "        for context, token in ngrams(self.n, text):\r\n",
        "            # keep count\r\n",
        "            if context in self.context_count_dic:\r\n",
        "                self.context_count_dic[context] += 1\r\n",
        "            else:\r\n",
        "                self.context_count_dic[context] = 1\r\n",
        "\r\n",
        "            # insert data\r\n",
        "            if context in self.context_dic:\r\n",
        "                token_dic = self.context_dic.get(context)\r\n",
        "                if token in token_dic:\r\n",
        "                    token_dic[token] += 1\r\n",
        "                else:\r\n",
        "                    token_dic[token] = 1\r\n",
        "            else:\r\n",
        "                self.context_dic[context] = {token: 1}\r\n",
        "        return\r\n",
        "\r\n",
        "    def prob(self, context, char):\r\n",
        "        ''' Returns the probability of char appearing after context '''\r\n",
        "        if context in self.context_dic:\r\n",
        "            token_dic = self.context_dic[context]\r\n",
        "            if char in token_dic:\r\n",
        "                return float(token_dic[char]) / self.context_count_dic[context]\r\n",
        "            else:\r\n",
        "                return 0.001\r\n",
        "        else:\r\n",
        "            return 0.001\r\n",
        "\r\n",
        "    def random_char(self, context):\r\n",
        "        ''' Returns a random character based on the given context and the \r\n",
        "            n-grams learned by this model '''\r\n",
        "        r = random.random()\r\n",
        "\r\n",
        "        if context in self.context_dic:\r\n",
        "            denominator = self.context_count_dic[context]\r\n",
        "            token_dic = self.context_dic[context]\r\n",
        "            sorted_keys = sorted(token_dic.keys())\r\n",
        "\r\n",
        "            for i, token in enumerate(sorted_keys):\r\n",
        "                minus_i_sum = sum([token_dic[k] for k in sorted_keys[:i]])\r\n",
        "                if float(minus_i_sum)/denominator <= r < float(minus_i_sum + token_dic[sorted_keys[i]])/denominator:\r\n",
        "                    return token\r\n",
        "\r\n",
        "        else:\r\n",
        "            return None\r\n",
        "\r\n",
        "    def random_text(self, length):\r\n",
        "        ''' Returns text of the specified character length based on the\r\n",
        "            n-grams learned by this model '''\r\n",
        "        if self.n != 1:\r\n",
        "            context = \"\".join([\"~\"] * (self.n))\r\n",
        "            generated = []\r\n",
        "\r\n",
        "            for __ in range(length):\r\n",
        "                token = self.random_char(context)\r\n",
        "                generated.append(token)\r\n",
        "\r\n",
        "                if token != \".\":\r\n",
        "                    context = context[1:] + (token)\r\n",
        "                else:\r\n",
        "                    context = \"\".join([\"~\"] * (self.n))\r\n",
        "\r\n",
        "            return \"\".join(generated)\r\n",
        "        else:\r\n",
        "            return \"\".join(self.random_char(random.choice(list(self.get_vocab()))) for _ in range(length))\r\n",
        "\r\n",
        "    def perplexity(self, text):\r\n",
        "        ''' Returns the perplexity of text based on the n-grams learned by\r\n",
        "            this model '''\r\n",
        "        product = 0\r\n",
        "\r\n",
        "        for context, token in ngrams(self.n, text):\r\n",
        "          if self.prob(context,token) != 0:\r\n",
        "            product += math.log(self.prob(context, token))\r\n",
        "        return (1/math.exp(product)) ** (float(1)/(len(text)+1))"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "himy0KlgydFM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d_A_aRPrs2M4"
      },
      "source": [
        "## Test Part\r\n",
        "\r\n",
        "### 1 Basic n-gram Models\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I1g7aRqL5GkF"
      },
      "source": [
        "n = NgramModel(1,0)\r\n",
        "n.update('abab')"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vZvX-t5i5VEs",
        "outputId": "e78e4179-3929-4a97-8e46-293469d5af79"
      },
      "source": [
        "print(n.perplexity('ab'))\r\n",
        "print(n.perplexity('cd'))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.2599210498948732\n",
            "999.9999999999994\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y0TIv6ms5RQR",
        "outputId": "96de46ee-2072-4b02-bdb4-76161398fcea"
      },
      "source": [
        "n.update('cd')\r\n",
        "n.perplexity('cd')"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.2599210498948732"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6AzUPp5is7Op",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "313de697-5b63-4f17-bbde-257488e22151"
      },
      "source": [
        "if __name__ == '__main__':\r\n",
        "  model1 = create_ngram_model(NgramModel, \"Baskaldiran-Insan-Albert-Camus.txt\", n=1)\r\n",
        "  model2 = create_ngram_model(NgramModel, \"Baskaldiran-Insan-Albert-Camus.txt\", n=2)\r\n",
        "  model3 = create_ngram_model(NgramModel, \"Baskaldiran-Insan-Albert-Camus.txt\", n=3)\r\n",
        "  model4 = create_ngram_model(NgramModel, \"Baskaldiran-Insan-Albert-Camus.txt\", n=4)\r\n",
        "  model5 = create_ngram_model(NgramModel, \"Baskaldiran-Insan-Albert-Camus.txt\", n=5)\r\n",
        "  model6 = create_ngram_model(NgramModel, \"Baskaldiran-Insan-Albert-Camus.txt\", n=6)\r\n",
        "  model7 = create_ngram_model(NgramModel, \"Baskaldiran-Insan-Albert-Camus.txt\", n=7)\r\n",
        "  model10 = create_ngram_model(NgramModel, \"Baskaldiran-Insan-Albert-Camus.txt\", n=10)\r\n",
        "  model15 = create_ngram_model(NgramModel, \"Baskaldiran-Insan-Albert-Camus.txt\", n=15)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "  print('============= Uni-gram =============')\r\n",
        "\r\n",
        "  #print(model1.get_vocab())\r\n",
        "  #print('-------')\r\n",
        "  print(model2.random_text(300))\r\n",
        "\r\n",
        "\r\n",
        "  print()\r\n",
        "  print('============= Bi-gram =============')\r\n",
        "\r\n",
        "  #print('-------')\r\n",
        "  print(model2.random_text(300))\r\n",
        "\r\n",
        "\r\n",
        "  print()\r\n",
        "  print('============= Tri-gram =============')\r\n",
        "\r\n",
        "  print(model3.random_text(300))\r\n",
        "\r\n",
        "\r\n",
        "  print()\r\n",
        "  print('============= Four-gram =============')\r\n",
        "\r\n",
        "  print(model4.random_text(300))\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "  print()\r\n",
        "  print('============= Five-gram =============')\r\n",
        "\r\n",
        "  print(model5.random_text(300))\r\n",
        "\r\n",
        "\r\n",
        "  print()\r\n",
        "  print('============= Six-gram =============')\r\n",
        "\r\n",
        "  print(model6.random_text(300))\r\n",
        "\r\n",
        "  print()\r\n",
        "  print('============= Seven-gram =============')\r\n",
        "\r\n",
        "  print(model7.random_text(300))\r\n",
        "\r\n",
        "\r\n",
        "  print()\r\n",
        "  print('============= Ten-gram =============')\r\n",
        "\r\n",
        "  print(model10.random_text(300))\r\n",
        "\r\n",
        "\r\n",
        "  print()\r\n",
        "  print('============= 15-gram =============')\r\n",
        "\r\n",
        "  print(model15.random_text(300))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "============= Uni-gram =============\n",
            "ALBEL Yaz, sün etizliklarx’ını birekmış düne sürmekişin böylendirde, l’e sözelerin ve de derçekmadırlüğü bu kalaraktu.ALTIK Kitiminek sonu bilirimir bulununları varçeğilerin kur, isinini bi, büyüzeyecekla dalışı olanınını eni ve (Konursledeği olarışılarış biganı düğü, bütülem olamak içimektık ta nay\n",
            "\n",
            "============= Bi-gram =============\n",
            "ALDIRI Ver.ALDÜLEME\n",
            "\n",
            "\n",
            "22.ALDIRICILDIRAN\n",
            "\n",
            "65 yazlıdanınaylabil, sürür kalı bilinide, sarderksindaynı.AL Yen Cebilerluğun Salyayaşkulurjuvartına deme yan eğin keninsayısındi.AL Yar ile, der, aşı am basın du.ALTIK Ve değ bır hak Tahaklaralıkım derileydı.ALDIRI\n",
            "\n",
            "Sonundir bilin, kirlarşılamamazlunu denda\n",
            "\n",
            "============= Tri-gram =============\n",
            "ALBERT CAMUS\n",
            "\n",
            "Böylemek belişmez, Tanrı örne, yargılaşmazlamı söylemiş olmayıcı gize.ALBERT CAMUS\n",
            "\n",
            "Bir şeyi ve ama tan yollanmıştır.ALBERT CAMUS\n",
            "\n",
            "Bakunur.ALBERT CAMUS, 1789 yen san bütününü söyle çevreniden bir şey uymaz aral Söyle başlı öldürmeye savaşı de konun emi bir bileri yılığı bir şey, Tarih \n",
            "\n",
            "============= Four-gram =============\n",
            "ALBERT CAMUS, 1945’te olup çıkardeşli sosyalist sorunlu açık gibi, bütün insan yazlığa, doldu mududur? Söylemini yadsıya gün olarak dolaylar yollardan üzerinde gelenenleriyle bir şeylemiştiğin Komünizm yarak yani gerekirdiği de kabul etmelidir.ALBERT CAMUS, 1914’te besleme Shakespearesinde böyler ve\n",
            "\n",
            "============= Five-gram =============\n",
            "ALBERT CAMUS\n",
            "\n",
            "BAŞKALDIRI\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Yıldıran sınıf kalıtçısı, acı gerçekleri de sıklaştırmayı yeğ tutarlılık belirtisi yumuşak filozofları için yerinin aynı zaman, ölüm cezasında, Hıristiyanları diye bilime doğruluğu için göbeğinden baş döndüğü, en sorusu yalnız, hayır’dan ağızdan önceden, değildir.ALBERT\n",
            "\n",
            "============= Six-gram =============\n",
            "ALBERT CAMUS, 1913 yılında, bu yaşayan tanrı olmuş bir suçlu kadar felsefi deneyimle, başkalarını kendilerini canlanan, titreyiş getiren Herzen’in biri 1933’te ise o olduğunda, belki de onun en yüksek mahkeme saldırının hiçbir ileri söz konusu, bilinen tarihsel suçsuzlukların sanatta yattığı köleler\n",
            "\n",
            "============= Seven-gram =============\n",
            "ALBERT CAMUS, 1913 yılında, ilkin kapitalizm bu üretim ve emeğinden yoksun bir kişinin, yani öbür uçta, var olması olabilecek umudu içinde, sonunda “Varız”ı, onunla el ele verici bir eylemi içinde bulunmaması olası, olması, anlamsızlaştı; hilebazlığının, tanrı geleneklere, nice eylemlerde biriktirir\n",
            "\n",
            "============= Ten-gram =============\n",
            "ALBERT CAMUS\n",
            "\n",
            "BAŞKALDIRAN İNSAN\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Kimdir başkaldırı ancak son insanların korkak olmaktan çıkacaktır.ALBERT CAMUS, 1913 yılında Cezayir’de görev alınır ve Prometheusçu mudur?\n",
            "\n",
            "İlk tanrıbilgiler, Prometheus değildir soylu olduklarından koparıp da genel yasanın altına atılarak bakanla birlikte, bu s\n",
            "\n",
            "============= 15-gram =============\n",
            "ALBERT CAMUS\n",
            "\n",
            "BAŞKALDIRAN\n",
            "\n",
            "İNSAN\n",
            "\n",
            "\n",
            "\n",
            "DENEME\n",
            "\n",
            "1957 NOBEL EDEBİYAT ÖDÜLÜ\n",
            "\n",
            "Fransızca aslından çeviren\n",
            "\n",
            "Tahsin Yücel\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Albert Camus’nün Can Yayınları’ndaki diğer kitapları:\n",
            "\n",
            "Yabancı, 1981\n",
            "\n",
            "Mutlu Ölüm, 1991\n",
            "\n",
            "Tersi ve Yüzü, 1992\n",
            "\n",
            "Yolculuk Günlükleri, 1993\n",
            "\n",
            "İlk Adam, 1994\n",
            "\n",
            "Yaz, 1994\n",
            "\n",
            "Düğün - Bir Alman Do\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oVEO4rH002vf",
        "outputId": "e53d5ca4-28c4-46d3-f37f-d3bb645d192f"
      },
      "source": [
        "model1.get_vocab()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['~', 'A', 'L', 'B', 'E', 'R', 'T', ' ', 'C', 'M', 'U', 'S', '\\n', 'Ş', 'K', 'D', 'I', 'N', 'İ', '1', '9', '5', '7', 'O', 'Y', 'Ö', 'Ü', 'F', 'r', 'a', 'n', 's', 'ı', 'z', 'c', 'l', 'd', 'ç', 'e', 'v', 'i', 'h', 'ü', 'b', 't', 'm', 'u', '’', 'y', 'k', 'ğ', 'p', ':', ',', '8', '2', 'o', 'G', '3', '4', '-', 'g', '6', 'f', 'ö', 'ş', 'V', '.', 'P', '“', '”', 'X', '0', 'H', '(', ')', 'J', 'x', 'é', 'Ç', 'q', 'â', ';', 'Z', '*', '?', '–', '!', 'î', 'j', 'Ğ', 'û', 'è', 'ê', 'w', '/', 'Q', 'W', '‘', 'Â'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "icZNEJZp05w4",
        "outputId": "8b83a25b-6e8c-4f1f-d951-29b29cd4cf47"
      },
      "source": [
        "print(model1.prob('A','l'))\r\n",
        "print(model1.random_char('A'))\r\n",
        "print(model1.perplexity(\"Yaz\"))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.10068649885583524\n",
            "m\n",
            "39.25554000250682\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zbX78woh4SSd"
      },
      "source": [
        ""
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s8XbQ1v35BSl"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}